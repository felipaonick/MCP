# ğŸ§  MCP + LangGraph: Esecuzione, Tool Calling e Tracciamento

## ğŸ¯ Obiettivo

Mostrare come un agente ReAct di LangGraph utilizza un MCP client per invocare tool remoti (esposti da un MCP server), mantenendo un'architettura modulare e decoupled.

---

## ğŸ” Flusso completo di esecuzione (2+2)

### âœ… 1. Esecuzione di `main.py`

* Sessione inizializzata âœ…
* Richiesta `list_tools` gestita âœ…
* Richiesta `call_tool` eseguita âœ…

> Lâ€™agente ReAct di LangGraph agisce come **host MCP** che usa il **client MCP** per invocare strumenti remoti.

---

## ğŸ” 2. Come funziona il flusso MCP

![alt](../images/mcp_flow.png)

### âœ³ï¸ Step-by-step:

1. **Utente invia una query** (es. `"What is 2 + 2?"`)
2. **LangGraph ReAct Agent** (MCP Host) riceve il prompt
3. Lâ€™agente invia al **LLM** (es. `ChatOpenAI`) il messaggio utente + lista degli MCP tool disponibili
4. Il **LLM risponde**: â€œChiama `add` con argomenti `2` e `2`â€
5. Il **client MCP** comunica con il **server MCP** (via `stdio` o `SSE`)
6. Il **server esegue** la funzione `add(2, 2)` e restituisce `4`
7. Il **client MCP** inoltra la risposta al **LangGraph Agent**
8. Lâ€™agente formatta la risposta finale e la invia al LLM per il completamento
9. Il **LLM** restituisce `"2 + 2 = 4"` come output finale
10. Il **LangGraph Agent** invia la risposta all'utente

âœ… **ResponsabilitÃ  separate**:

* **LangGraph** â†’ orchestrazione, interfaccia utente
* **MCP Server** â†’ esecuzione tool remota

---

## ğŸ§ª 3. Test piÃ¹ complesso: `54 + 2 * 3`

### ğŸ“¥ Prompt:

```text
What is 54 + 2 * 3?
```

### ğŸ“¤ Output:

```text
60
```

### ğŸ” Struttura delle invocazioni rilevate:

LangGraph ha effettuato **3 chiamate a strumenti**:

1. `multiply(2, 3)` â†’ `6`
2. `add(54, 0)` â†’ `54` â† â— Tool call inaspettata
3. `add(54, 6)` â†’ `60`

> ğŸ§  Questo comportamento mostra che LangGraph puÃ² effettuare **chiamate concorrenti** agli strumenti MCP.

---

## ğŸ“Š 4. Analisi con LangSmith Trace

### ğŸ“Œ Primo Esempio: `2 + 2`

* Tool chiamato: `add`
* Input: `2`, `2`
* Output: `4`
* Tool disponibili: `add`, `multiply`
* Prompt originale + tools inclusi nel payload del messaggio LLM

### ğŸ“Œ Secondo Esempio: `54 + 2 * 3`

* Tool chiamati:

  1. `add(54, 0)` â“
  2. `multiply(2, 3)` â†’ `6`
  3. `add(54, 6)` â†’ `60`

#### ğŸ§© Tool Call Misteriosa: `add(54, 0)`

* Origina da una prima interpretazione del modello LLM
* Eseguita in parallelo a `multiply(2, 3)` grazie al **supporto concorrente di LangGraph**
* Timestamp identici nel tracing confermano esecuzione simultanea

---

## ğŸ“ 5. Commit finale del codice

* Modifiche implementate in `main.py`
* Commit eseguito tramite **Cursor**
* Push su GitHub completato
* Artefatto accessibile nella branch corrente del repository

---

## âœ… Conclusione

| Componente          | ResponsabilitÃ                                                                 |
| ------------------- | ----------------------------------------------------------------------------- |
| **MCP Client**      | Comunica con il server, esegue i tool remoti                                  |
| **MCP Server**      | Espone tool (`add`, `multiply`) via `stdio` o `sse`                           |
| **LangGraph Agent** | Orchestrazione: riceve query, invia tool calls al client, aggrega le risposte |
| **LangSmith**       | Tracciamento dettagliato delle esecuzioni agent-based                         |

---

## ğŸ”® Approfondimenti futuri suggeriti

* ğŸ“Œ Come gestire tools con dipendenze sequenziali in LangGraph
* ğŸ§µ Differenza tra `ReAct`, `Conversational`, e `Tool-Calling Agents`
* ğŸŒ Hosting MCP server via `SSE` su Docker o Kubernetes
* ğŸ” Sicurezza nella comunicazione client-server MCP

---
